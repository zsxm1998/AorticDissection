{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d5f19d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import copy\n",
    "import  traceback\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "import numpy as np  # linear algebra\n",
    "import pydicom\n",
    "from pydicom.errors import InvalidDicomError\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from pydicom.uid import UID\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ec30c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_scan(path):\n",
    "    slices = [] #slices = [pydicom.dcmread(path + '/' + s) for s in filter(lambda x: x.endswith('.dcm'), os.listdir(path))]\n",
    "    for s in os.listdir(path):\n",
    "        if os.path.isdir(os.path.join(path, s)): #if not s.endswith('.dcm'):\n",
    "            continue\n",
    "        sl = pydicom.dcmread(os.path.join(path, s), force=True)\n",
    "        try:\n",
    "            sl_p = sl.pixel_array\n",
    "        except (AttributeError, InvalidDicomError):\n",
    "            traceback.print_exc()\n",
    "            print(f'\\tDelete {os.path.join(path, s)}')\n",
    "            os.remove(os.path.join(path, s))\n",
    "        else:\n",
    "            slices.append(sl)\n",
    "    slices.sort(key=lambda x: float(x.InstanceNumber))\n",
    "    return slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaa0f64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-100 500\n"
     ]
    }
   ],
   "source": [
    "window_width, window_level = 600, 200\n",
    "lower_b, upper_b = window_level - window_width//2, window_level + window_width//2\n",
    "print(lower_b, upper_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883aa1c6",
   "metadata": {},
   "source": [
    "# 1.阴性数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2720e77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印哪个病例没有2\n",
    "def print_no_cta(input_dir):\n",
    "    print(f'**********{input_dir}')\n",
    "    no_cta_list = []\n",
    "    for patient in sorted(os.listdir(input_dir)):\n",
    "        patient_path = os.path.join(input_dir, patient)\n",
    "        if os.path.isfile(patient_path): continue\n",
    "        if '2' not in os.listdir(patient_path):\n",
    "            no_cta_list.append(patient_path)\n",
    "            print(patient_path, os.listdir(patient_path))\n",
    "            continue\n",
    "        if f'images_{lower_b}_{upper_b}' not in os.listdir(os.path.join(patient_path, '2')):\n",
    "            print(f'have 2 but not have images_{lower_b}_{upper_b}', patient_path)\n",
    "    return no_cta_list\n",
    "            \n",
    "no_cta_list = []\n",
    "no_cta_list.extend(print_no_cta('/nfs3-p2/zsxm/dataset/2021-9-17-negative'))\n",
    "no_cta_list.extend(print_no_cta('/nfs3-p2/zsxm/dataset/2021-9-29-negative'))\n",
    "print(no_cta_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f310245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#将某个scan重命名为2，如果thickness距离1的thickness相同则选择thickness小的重命名\n",
    "for patient in no_cta_list:\n",
    "    scans = os.listdir(patient)\n",
    "    if '1' not in scans:\n",
    "        print(patient, 'not have 1')\n",
    "        continue\n",
    "    if len(scans) == 2:\n",
    "        for scan in scans:\n",
    "            if scan != '1':\n",
    "                os.rename(os.path.join(patient, scan), os.path.join(patient, '2'))\n",
    "    else:\n",
    "        tk_list = []\n",
    "        for scan in scans:\n",
    "            for s in os.listdir(os.path.join(patient, scan)):\n",
    "                if os.path.isdir(os.path.join(patient, scan, s)) or not s.endswith('.dcm'):\n",
    "                    continue\n",
    "                sl = pydicom.dcmread(os.path.join(patient, scan, s))\n",
    "                try:\n",
    "                    sl_p = sl.pixel_array\n",
    "                except AttributeError:\n",
    "                    continue\n",
    "                else:\n",
    "                    if scan == '1':\n",
    "                        ct_thickness = sl.SliceThickness\n",
    "                    else:\n",
    "                        tk_list.append((sl.SliceThickness, scan))\n",
    "        min_dis, min_scan, min_tk = 10000, None, 10000\n",
    "        for tk, scan in tk_list:\n",
    "            dis = abs(tk-ct_thickness)\n",
    "            if dis < min_dis or (dis == min_dis and tk < min_tk):\n",
    "                min_dis, min_scan, min_tk = dis, scan, tk\n",
    "        print(patient, min_scan)\n",
    "        os.rename(os.path.join(patient, min_scan), os.path.join(patient, '2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad8ce0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将2下的dcm文件根据窗宽窗位转化为png图片\n",
    "def generate_image(input_folder):\n",
    "    for patient in sorted(os.listdir(input_folder)):\n",
    "        if os.path.isfile(os.path.join(input_folder, patient)) or f'images_{lower_b}_{upper_b}' in os.listdir(os.path.join(input_folder, patient, '2')):\n",
    "            continue\n",
    "        print(f'****Processing {patient}****')\n",
    "        for scan in os.listdir(os.path.join(input_folder, patient)):\n",
    "            if scan != '2':\n",
    "                continue\n",
    "            name = patient #name = patient.split('-')[0]\n",
    "            image_path = os.path.join(input_folder, patient, scan, f'images_{lower_b}_{upper_b}')\n",
    "            if os.path.exists(image_path):\n",
    "                shutil.rmtree(image_path)\n",
    "            os.mkdir(image_path)\n",
    "\n",
    "            ct = load_scan(os.path.join(input_folder, patient, scan))\n",
    "            print_flag = False\n",
    "            for i in range(len(ct)):\n",
    "                img = ct[i].pixel_array.astype(np.int16)\n",
    "                intercept = ct[i].RescaleIntercept\n",
    "                slope = ct[i].RescaleSlope\n",
    "                if slope != 1:\n",
    "                    img = (slope * img.astype(np.float64)).astype(np.int16)\n",
    "                img += np.int16(intercept)\n",
    "                img = np.clip(img, lower_b, upper_b)\n",
    "                img = ((img-lower_b)/(upper_b-lower_b)*255).astype(np.uint8)\n",
    "                img = Image.fromarray(img)\n",
    "                if img.height != img.width:\n",
    "                    if not print_flag:\n",
    "                        print(patient, f'height({img.height}) not equal to width({img.width})\\n')\n",
    "                        print_flag = True\n",
    "                    height = width = min(img.height, img.width)\n",
    "                    if img.height != height:\n",
    "                        start = (img.height - height) / 2\n",
    "                        img = img.crop((0, start, img.width, start + height))\n",
    "                    elif img.width != width:\n",
    "                        start = (img.width - width) / 2\n",
    "                        img = img.crop((start, 0, start + height, img.height))\n",
    "                img.save(os.path.join(image_path, f'{name}_{i:04d}.png'))\n",
    "\n",
    "generate_image('/nfs3-p1/zsxm/dataset/2021-9-17-negative/')\n",
    "generate_image('/nfs3-p1/zsxm/dataset/2021-9-29-negative/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1cd315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将各个病例中的png图片文件夹统一移动到一起供yolov5检测, not_move=True表示若有labels则不移动去检测\n",
    "def move_together_for_detect(input_folder, dst_path, not_move=True):   \n",
    "    if not os.path.exists(dst_path):\n",
    "        os.mkdir(dst_path)\n",
    "    root_name = input_folder.split('/')[-1] if input_folder.split('/')[-1] != '' else input_folder.split('/')[-2]\n",
    "    dst_path = os.path.join(dst_path, root_name)\n",
    "\n",
    "    for patient in sorted(os.listdir(input_folder)):\n",
    "        if os.path.isfile(os.path.join(input_folder, patient)):\n",
    "            continue\n",
    "        if not_move and os.path.exists(os.path.join(input_folder, patient, '2', 'labels'))\n",
    "        and os.path.exists(os.path.join(input_folder, patient, '2', f'pred_images_{lower_b}_{upper_b}')):\n",
    "            continue\n",
    "        print(f'****Processing {patient}****')\n",
    "        name = patient #name = patient.split('-')[0]\n",
    "        if os.path.exists(os.path.join(dst_path, name)):\n",
    "            print(f\"\\tremove {os.path.join(dst_path, name)}\")\n",
    "            shutil.rmtree(os.path.join(dst_path, name))\n",
    "\n",
    "        try:\n",
    "            shutil.copytree(os.path.join(input_folder, patient, '2', f'images_{lower_b}_{upper_b}'), os.path.join(dst_path, name))\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "\n",
    "move_together_for_detect('/nfs3-p1/zsxm/dataset/2021-9-17-negative/', '/nfs3-p1/zsxm/dataset/9_detect/')\n",
    "move_together_for_detect('/nfs3-p1/zsxm/dataset/2021-9-29-negative/', '/nfs3-p1/zsxm/dataset/9_detect/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b97314",
   "metadata": {},
   "outputs": [],
   "source": [
    "#将检测结果移动回原文件夹内\n",
    "def move_back(result_path, ori_path):\n",
    "    if not os.path.exists(result_path):\n",
    "        print(f'目录不存在：{result_path}')\n",
    "        return\n",
    "    for patient in sorted(os.listdir(result_path)):\n",
    "        print(f'Processing {patient}')\n",
    "        p_res_path = os.path.join(result_path, patient)\n",
    "        o_res_path = os.path.join(ori_path, patient, '2', f'pred_images_{lower_b}_{upper_b}')\n",
    "        if os.path.exists(o_res_path):\n",
    "            shutil.rmtree(o_res_path)\n",
    "        os.mkdir(o_res_path)\n",
    "        for file in os.listdir(p_res_path):\n",
    "            if os.path.isfile(os.path.join(p_res_path, file)):\n",
    "                shutil.move(os.path.join(p_res_path, file), os.path.join(o_res_path, file))\n",
    "            elif os.path.isdir(os.path.join(p_res_path, file)):\n",
    "                if os.path.exists(os.path.join(ori_path, patient, '2', file)):\n",
    "                    shutil.rmtree(os.path.join(ori_path, patient, '2', file))\n",
    "                shutil.move(os.path.join(p_res_path, file), os.path.join(ori_path, patient, '2', file))\n",
    "        os.rmdir(p_res_path)\n",
    "    os.rmdir(result_path)\n",
    "                \n",
    "move_back('/home/zsxm/pythonWorkspace/yolov5_old/runs/detect/2021-9-17-negative', '/nfs3-p1/zsxm/dataset/2021-9-17-negative/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b1176f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切出主动脉,这里有问题啊，branch_end前后0.3的切片切不出来，建议以后更改为和下面一样的方案\n",
    "def find_coordinate(height, width, label_file, aorta):\n",
    "    with open(label_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    assert len(lines) <= 2, f'label.txt应该存储不多于2个label：{label_file.split(\"/\")[-1]}'\n",
    "    if len(lines) == 1:\n",
    "        assert aorta == 'j', f'如果只有一个label那么此时应为降主动脉, 但实际为{aorta}：{label_file.split(\"/\")[-1]}'\n",
    "        corr = list(map(lambda x: float(x), lines[0].split()))\n",
    "        x, y, w, h = corr[1], corr[2], corr[3], corr[4]\n",
    "        assert 0.25 < x < 0.75 and 0.2 < y < 0.8, f'边界框中心({x}, {y})出界：{label_file.split(\"/\")[-1]}'\n",
    "    else:\n",
    "        corr1, corr2 = list(map(lambda x: float(x), lines[0].split())), list(map(lambda x: float(x), lines[1].split()))\n",
    "        assert 0.25 < corr1[1] < 0.75 and 0.2 < corr1[2] < 0.8, f'边界框1中心({corr1[1]}, {corr1[2]})出界：{label_file.split(\"/\")[-1]}'\n",
    "        assert 0.25 < corr2[1] < 0.75 and 0.2 < corr2[2] < 0.8, f'边界框2中心({corr2[1]}, {corr2[2]})出界：{label_file.split(\"/\")[-1]}'\n",
    "        if aorta == 's':\n",
    "            x, y, w, h = (corr1[1], corr1[2], corr1[3], corr1[4]) if corr1[2] < corr2[2] else (corr2[1], corr2[2], corr2[3], corr2[4])\n",
    "        elif aorta == 'j':\n",
    "            x, y, w, h = (corr1[1], corr1[2], corr1[3], corr1[4]) if corr1[2] > corr2[2] else (corr2[1], corr2[2], corr2[3], corr2[4])\n",
    "        else:\n",
    "            raise Exception(f'aorta 应该为\"s\"或\"j\"其中之一: {label_file.split(\"/\")[-1]}')\n",
    "    w, h = int(width*w), int(height*h)\n",
    "    w, h = max(w, h), max(w, h)\n",
    "    return int(width*x-w/2), int(height*y-h/2), int(width*x+w/2+1), int(height*y+h/2+1)\n",
    "\n",
    "def crop_images(input_path, error_patient_list):\n",
    "    workbook_path = os.path.join(input_path, 'label.xlsx')\n",
    "    wb = openpyxl.load_workbook(workbook_path)\n",
    "    sheet = wb['Sheet1']\n",
    "    \n",
    "    for patient in sorted(os.listdir(input_path)):\n",
    "        if os.path.isfile(os.path.join(input_path, patient)):\n",
    "            continue\n",
    "        flag = True\n",
    "        for row in sheet.iter_rows():\n",
    "            if row[0].value == patient.split('-')[0]:\n",
    "                if row[3].value is not None and row[4].value is not None:\n",
    "                    flag = False\n",
    "                    ls = row[4].value.split('-')\n",
    "                    assert len(ls) == 4, f'{patient} ls wrong'\n",
    "                    aorta_start, branch_start = int(ls[0])-1, int(ls[1])-1\n",
    "                    branch_end, aorta_end = int(ls[2])-1, int(ls[3])-1\n",
    "                    lsct = row[3].value.split('-')\n",
    "                    assert len(lsct) == 4, f'{patient} lsct wrong'\n",
    "                    ct_start, ct_end = int(lsct[0])-1, int(lsct[3])-1\n",
    "                break\n",
    "        if flag: continue\n",
    "        print(f'******Processing {patient}******')\n",
    "        image_path = os.path.join(input_path, patient, '2', f'images_{lower_b}_{upper_b}')\n",
    "        label_path = os.path.join(input_path, patient, '2', 'labels')\n",
    "        crop_path = os.path.join(input_path, patient, '2', f'crops_{lower_b}_{upper_b}')\n",
    "        if os.path.exists(crop_path):\n",
    "            shutil.rmtree(crop_path)\n",
    "        os.mkdir(crop_path)\n",
    "        \n",
    "        crop_flag = True\n",
    "        offset = branch_end - branch_start\n",
    "        start, end = branch_start + int(0.1*offset), branch_end - int(0.2*offset)\n",
    "        for i in range(start, end):\n",
    "            img = Image.open(os.path.join(image_path, f'{patient}_{i:04d}.png'))\n",
    "            img = np.array(img)\n",
    "            try:\n",
    "                x1, y1, x2, y2 = find_coordinate(*img.shape[0:2], os.path.join(label_path, f'{patient}_{i:04d}.txt'), 's')\n",
    "            except:\n",
    "                traceback.print_exc()\n",
    "                crop_flag = False\n",
    "            else:#if crop_flag:\n",
    "                crop = img[y1:y2, x1:x2]\n",
    "                crop = Image.fromarray(crop)\n",
    "                crop.save(os.path.join(crop_path, f'{patient}_s_{i:04d}.png'))\n",
    "            try:\n",
    "                x1, y1, x2, y2 = find_coordinate(*img.shape[0:2], os.path.join(label_path, f'{patient}_{i:04d}.txt'), 'j')\n",
    "            except:\n",
    "                traceback.print_exc()\n",
    "                crop_flag = False\n",
    "            else:#if crop_flag:\n",
    "                crop = img[y1:y2, x1:x2]\n",
    "                crop = Image.fromarray(crop)\n",
    "                crop.save(os.path.join(crop_path, f'{patient}_j_{i:04d}.png'))\n",
    "        offset = aorta_end - branch_end\n",
    "        start, end = branch_end + int(0.1*offset), aorta_end - int(0.2*offset)\n",
    "        for i in range(start, end):\n",
    "            img = Image.open(os.path.join(image_path, f'{patient}_{i:04d}.png'))\n",
    "            img = np.array(img)\n",
    "            try:\n",
    "                x1, y1, x2, y2 = find_coordinate(*img.shape[0:2], os.path.join(label_path, f'{patient}_{i:04d}.txt'), 'j')\n",
    "            except:\n",
    "                traceback.print_exc()\n",
    "                crop_flag = False\n",
    "            else:#if crop_flag:\n",
    "                crop = img[y1:y2, x1:x2]\n",
    "                crop = Image.fromarray(crop)\n",
    "                crop.save(os.path.join(crop_path, f'{patient}_j_{i:04d}.png'))\n",
    "        if not crop_flag:\n",
    "            error_patient_list.append(patient)\n",
    "            \n",
    "epl1 = []\n",
    "crop_images('/nfs3-p1/zsxm/dataset/2021-9-17-negative/', epl1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d39935",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(epl1))\n",
    "print(epl1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd7e476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切出范围外冗余为3的主动脉\n",
    "def find_coordinate(height, width, label_file, aorta):\n",
    "    with open(label_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    assert len(lines) <= 2, f'label.txt应该存储不多于2个label：{label_file.split(\"/\")[-1]}'\n",
    "    if len(lines) == 1:\n",
    "        assert aorta == 'j', f'如果只有一个label那么此时应为降主动脉, 但实际为{aorta}：{label_file.split(\"/\")[-1]}'\n",
    "        corr = list(map(lambda x: float(x), lines[0].split()))\n",
    "        x, y, w, h = corr[1], corr[2], corr[3], corr[4]\n",
    "        assert 0.25 < x < 0.75 and 0.2 < y < 0.8, f'边界框中心({x}, {y})出界：{label_file.split(\"/\")[-1]}'\n",
    "    else:\n",
    "        corr1, corr2 = list(map(lambda x: float(x), lines[0].split())), list(map(lambda x: float(x), lines[1].split()))\n",
    "        assert 0.25 < corr1[1] < 0.75 and 0.2 < corr1[2] < 0.8, f'边界框1中心({corr1[1]}, {corr1[2]})出界：{label_file.split(\"/\")[-1]}'\n",
    "        assert 0.25 < corr2[1] < 0.75 and 0.2 < corr2[2] < 0.8, f'边界框2中心({corr2[1]}, {corr2[2]})出界：{label_file.split(\"/\")[-1]}'\n",
    "        if aorta == 's':\n",
    "            x, y, w, h = (corr1[1], corr1[2], corr1[3], corr1[4]) if corr1[2] < corr2[2] else (corr2[1], corr2[2], corr2[3], corr2[4])\n",
    "        elif aorta == 'j':\n",
    "            x, y, w, h = (corr1[1], corr1[2], corr1[3], corr1[4]) if corr1[2] > corr2[2] else (corr2[1], corr2[2], corr2[3], corr2[4])\n",
    "        else:\n",
    "            raise Exception(f'aorta 应该为\"s\"或\"j\"其中之一: {label_file.split(\"/\")[-1]}')\n",
    "    w, h = int(width*w), int(height*h)\n",
    "    w, h = max(w, h), max(w, h)\n",
    "    return int(width*x-w/2), int(height*y-h/2), int(width*x+w/2+1), int(height*y+h/2+1)\n",
    "\n",
    "def crop_images(input_path, error_patient_list):\n",
    "    workbook_path = os.path.join(input_path, 'label.xlsx')\n",
    "    wb = openpyxl.load_workbook(workbook_path)\n",
    "    sheet = wb['Sheet1']\n",
    "    \n",
    "    for patient in sorted(os.listdir(input_path)):\n",
    "        if os.path.isfile(os.path.join(input_path, patient)):\n",
    "            continue\n",
    "        flag = True\n",
    "        for row in sheet.iter_rows():\n",
    "            if row[0].value == patient.split('-')[0]:\n",
    "                if row[3].value is not None and row[4].value is not None:\n",
    "                    flag = False\n",
    "                    ls = row[4].value.split('-')\n",
    "                    assert len(ls) == 4, f'{patient} ls wrong'\n",
    "                    aorta_start, branch_start = int(ls[0])-1, int(ls[1])-1\n",
    "                    branch_end, aorta_end = int(ls[2])-1, int(ls[3])-1\n",
    "                break\n",
    "        if flag: continue\n",
    "        print(f'******Processing {patient}******')\n",
    "        image_path = os.path.join(input_path, patient, '2', f'images_{lower_b}_{upper_b}')\n",
    "        label_path = os.path.join(input_path, patient, '2', 'labels')\n",
    "        crop_path = os.path.join(input_path, patient, '2', f'crops3_{lower_b}_{upper_b}')\n",
    "        if os.path.exists(crop_path):\n",
    "            shutil.rmtree(crop_path)\n",
    "        os.mkdir(crop_path)\n",
    "        \n",
    "        crop_flag = True\n",
    "        offset = branch_end - branch_start\n",
    "        start, end = branch_start + int(0.1*offset), branch_end - int(0.2*offset)\n",
    "        for i in range(start-3, end+3):\n",
    "            try:\n",
    "                img = Image.open(os.path.join(image_path, f'{patient}_{i:04d}.png'))\n",
    "                img = np.array(img)\n",
    "                x1, y1, x2, y2 = find_coordinate(*img.shape[0:2], os.path.join(label_path, f'{patient}_{i:04d}.txt'), 's')\n",
    "            except:\n",
    "                traceback.print_exc()\n",
    "                crop_flag = False\n",
    "            else:#if crop_flag:\n",
    "                crop = img[y1:y2, x1:x2]\n",
    "                crop = Image.fromarray(crop)\n",
    "                if start <= i < end:\n",
    "                    crop.save(os.path.join(crop_path, f'{patient}_s_{i:04d}.png'))\n",
    "                else:\n",
    "                    crop.save(os.path.join(crop_path, f'{patient}_s_{i:04d}_n.png'))\n",
    "        offset = aorta_end - branch_start\n",
    "        start, end = branch_start + int(0.05*offset), aorta_end - int(0.1*offset)\n",
    "        for i in range(start-3, end+3):\n",
    "            try:\n",
    "                img = Image.open(os.path.join(image_path, f'{patient}_{i:04d}.png'))\n",
    "                img = np.array(img)\n",
    "                x1, y1, x2, y2 = find_coordinate(*img.shape[0:2], os.path.join(label_path, f'{patient}_{i:04d}.txt'), 'j')\n",
    "            except:\n",
    "                traceback.print_exc()\n",
    "                crop_flag = False\n",
    "            else:#if crop_flag:\n",
    "                crop = img[y1:y2, x1:x2]\n",
    "                crop = Image.fromarray(crop)\n",
    "                if start <= i < end:\n",
    "                    crop.save(os.path.join(crop_path, f'{patient}_j_{i:04d}.png'))\n",
    "                else:\n",
    "                    crop.save(os.path.join(crop_path, f'{patient}_j_{i:04d}_n.png'))\n",
    "        if not crop_flag:\n",
    "            error_patient_list.append(patient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420033c2",
   "metadata": {},
   "source": [
    "# 2.疾病数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d259d00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印哪个病例没有2\n",
    "def print_no_cta(input_dir):\n",
    "    print(f'**********{input_dir}')\n",
    "    no_cta_list = []\n",
    "    for patient in sorted(os.listdir(input_dir)):\n",
    "        patient_path = os.path.join(input_dir, patient)\n",
    "        if os.path.isfile(patient_path): continue\n",
    "        if '2' not in os.listdir(patient_path):\n",
    "            no_cta_list.append(patient_path)\n",
    "            print(patient_path, os.listdir(patient_path))\n",
    "            continue\n",
    "        if f'images_{lower_b}_{upper_b}' not in os.listdir(os.path.join(patient_path, '2')):\n",
    "            print(f'have 2 but not have images_{lower_b}_{upper_b}', patient_path)\n",
    "    return no_cta_list\n",
    "\n",
    "no_cta_list = []\n",
    "no_cta_list.extend(print_no_cta('/nfs3-p1/zsxm/dataset/2021-9-8'))\n",
    "no_cta_list.extend(print_no_cta('/nfs3-p1/zsxm/dataset/2021-9-13/'))\n",
    "no_cta_list.extend(print_no_cta('/nfs3-p1/zsxm/dataset/2021-9-19/'))\n",
    "no_cta_list.extend(print_no_cta('/nfs3-p1/zsxm/dataset/2021-9-28/'))\n",
    "no_cta_list.extend(print_no_cta('/nfs3-p2/zsxm/dataset/2021-10-19-imh/'))\n",
    "no_cta_list.extend(print_no_cta('/nfs3-p2/zsxm/dataset/2021-10-19-pau/'))\n",
    "no_cta_list.extend(print_no_cta('/nfs3-p2/zsxm/dataset/2021-10-19-aa/'))\n",
    "no_cta_list.extend(print_no_cta('/nfs3-p2/zsxm/dataset/2021-11-20/'))\n",
    "no_cta_list.extend(print_no_cta('/nfs3-p2/zsxm/dataset/2021-11-20-imh/'))\n",
    "no_cta_list.extend(print_no_cta('/nfs3-p2/zsxm/dataset/2021-11-20-pau/'))\n",
    "print(no_cta_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b1c5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#将某个scan重命名为2，如果thickness距离1的thickness相同则选择thickness小的重命名\n",
    "for patient in no_cta_list:\n",
    "    scans = os.listdir(patient)\n",
    "    if '1' not in scans:\n",
    "        print(patient, 'not have 1')\n",
    "        continue\n",
    "    if len(scans) == 2:\n",
    "        for scan in scans:\n",
    "            if scan != '1':\n",
    "                os.rename(os.path.join(patient, scan), os.path.join(patient, '2'))\n",
    "    else:\n",
    "        tk_list = []\n",
    "        for scan in scans:\n",
    "            for s in os.listdir(os.path.join(patient, scan)):\n",
    "                if os.path.isdir(os.path.join(patient, scan, s)) or not s.endswith('.dcm'):\n",
    "                    continue\n",
    "                sl = pydicom.dcmread(os.path.join(patient, scan, s))\n",
    "                try:\n",
    "                    sl_p = sl.pixel_array\n",
    "                except AttributeError:\n",
    "                    continue\n",
    "                else:\n",
    "                    if scan == '1':\n",
    "                        ct_thickness = sl.SliceThickness\n",
    "                    else:\n",
    "                        tk_list.append((sl.SliceThickness, scan))\n",
    "        min_dis, min_scan, min_tk = 10000, None, 10000\n",
    "        for tk, scan in tk_list:\n",
    "            dis = abs(tk-ct_thickness)\n",
    "            if dis < min_dis or (dis == min_dis and tk < min_tk):\n",
    "                min_dis, min_scan, min_tk = dis, scan, tk\n",
    "        print(patient, min_scan)\n",
    "        os.rename(os.path.join(patient, min_scan), os.path.join(patient, '2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64115f1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 将2下的dcm文件根据窗宽窗位转化为png图片\n",
    "def generate_image(input_folder):\n",
    "    for patient in sorted(os.listdir(input_folder)):\n",
    "        if os.path.isfile(os.path.join(input_folder, patient)):\n",
    "            continue\n",
    "        print(f'****Processing {patient}****')\n",
    "        for scan in os.listdir(os.path.join(input_folder, patient)):\n",
    "            if scan != '2':\n",
    "                continue\n",
    "            name = patient #name = patient.split('-')[0]\n",
    "            image_path = os.path.join(input_folder, patient, scan, f'images_{lower_b}_{upper_b}')\n",
    "            if os.path.exists(image_path):\n",
    "                shutil.rmtree(image_path)\n",
    "            os.mkdir(image_path)\n",
    "\n",
    "            ct = load_scan(os.path.join(input_folder, patient, scan))\n",
    "            print_flag = False\n",
    "            for i in range(len(ct)):\n",
    "                img = ct[i].pixel_array.astype(np.int16)\n",
    "                intercept = ct[i].RescaleIntercept\n",
    "                slope = ct[i].RescaleSlope\n",
    "                if slope != 1:\n",
    "                    img = (slope * img.astype(np.float64)).astype(np.int16)\n",
    "                img += np.int16(intercept)\n",
    "                img = np.clip(img, lower_b, upper_b)\n",
    "                img = ((img-lower_b)/(upper_b-lower_b)*255).astype(np.uint8)\n",
    "                img = Image.fromarray(img)\n",
    "                if img.height != img.width:\n",
    "                    if not print_flag:\n",
    "                        print(patient, f'height({img.height}) not equal to width({img.width})\\n')\n",
    "                        print_flag = True\n",
    "                    height = width = min(img.height, img.width)\n",
    "                    if img.height != height:\n",
    "                        start = (img.height - height) / 2\n",
    "                        img = img.crop((0, start, img.width, start + height))\n",
    "                    elif img.width != width:\n",
    "                        start = (img.width - width) / 2\n",
    "                        img = img.crop((start, 0, start + height, img.height))\n",
    "                img.save(os.path.join(image_path, f'{name}_{i:04d}.png'))\n",
    "\n",
    "generate_image('/nfs3-p1/zsxm/dataset/2021-9-8/')\n",
    "print('----------------------------------------------------------------------------')\n",
    "generate_image('/nfs3-p1/zsxm/dataset/2021-9-13/')\n",
    "print('----------------------------------------------------------------------------')\n",
    "generate_image('/nfs3-p1/zsxm/dataset/2021-9-19/')\n",
    "print('----------------------------------------------------------------------------')\n",
    "generate_image('/nfs3-p1/zsxm/dataset/2021-9-28/')\n",
    "print('----------------------------------------------------------------------------')\n",
    "generate_image('/nfs3-p2/zsxm/dataset/2021-10-19-aa/')\n",
    "print('----------------------------------------------------------------------------')\n",
    "generate_image('/nfs3-p2/zsxm/dataset/2021-10-19-imh/')\n",
    "print('----------------------------------------------------------------------------')\n",
    "generate_image('/nfs3-p2/zsxm/dataset/2021-10-19-pau/')\n",
    "print('----------------------------------------------------------------------------')\n",
    "generate_image('/nfs3-p2/zsxm/dataset/2021-11-20/')\n",
    "print('----------------------------------------------------------------------------')\n",
    "generate_image('/nfs3-p2/zsxm/dataset/2021-11-20-imh/')\n",
    "print('----------------------------------------------------------------------------')\n",
    "generate_image('/nfs3-p2/zsxm/dataset/2021-11-20-pau/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2eee6b50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****Processing baoyin-S-Im9-22-J-Im9-68****\n",
      "****Processing caijilu-J-Im41-87****\n",
      "****Processing caimeiju-J-Im21-81****\n",
      "****Processing caiying-J-Im34-52****\n",
      "****Processing chengdazhong-J-Im24-38****\n",
      "****Processing chenglongdeng-S-Im21-33-J-Im21-78****\n",
      "****Processing chenguorong-J-Im18-77****\n",
      "****Processing chenjian-J-Im14-81****\n",
      "****Processing chenjinfa-J-Im34-105****\n",
      "****Processing chenmimao-S-Im32-40****\n",
      "****Processing chenrugu-J-Im21-79****\n",
      "****Processing chensheng-J-Im31-91****\n",
      "****Processing chenweimin-J-Im20-36****\n",
      "****Processing chenwenhua-J-Im41-158****\n",
      "****Processing chenxiaoxiang-J-Im23-88****\n",
      "****Processing chenxuehua-S-Im17-27-J-Im17-35****\n",
      "****Processing chenyicong-J-Im17-58****\n",
      "****Processing dingliyun-J-Im19-57****\n",
      "****Processing dongzhigen-J-Im22-102****\n",
      "****Processing fanghao-J-Im23-89****\n",
      "****Processing fanlanhua-J-Im26-116****\n",
      "****Processing fanxinan-S-Im16-36-J-Im16-30****\n",
      "****Processing gongyongfa-S-Im18-34-J-Im18-87****\n",
      "****Processing heyuexiang-J-Im18-76****\n",
      "****Processing hezhangquan-J-Im33-58****\n",
      "****Processing huangdebing-S-Im40-48-J-Im33-138****\n",
      "****Processing huanghai-S-Im19-29-J-Im19-80****\n",
      "****Processing huangsuyue-J-Im21-41****\n",
      "****Processing huangyong-J-Im18-127****\n",
      "****Processing huchaoming-J-Im43-126****\n",
      "****Processing jiangjianchun-J-Im31-151****\n",
      "****Processing jilixian-J-Im34-108****\n",
      "****Processing jinfajun-J-Im22-72****\n",
      "****Processing jiushan-S-Im21-30-J-Im21-82****\n",
      "****Processing laixuexiang-J-Im33-148****\n",
      "****Processing lanshaomei-S-Im20-31-J-Im20-79****\n",
      "****Processing leitufa-S-Im30-60-J-Im30-117****\n",
      "****Processing leixiaoying-S-Im18-26-J-18-71****\n",
      "****Processing liangjianhua-J-Im18-75****\n",
      "****Processing lidaoheng-S-Im22-36-J-Im22-92****\n",
      "****Processing lihuanhuan-S-Im20-28-J-Im20-59****\n",
      "****Processing lijianming-J-Im32-124****\n",
      "****Processing lingenqiang-S-Im30-39****\n",
      "****Processing lingshounv-S-Im18-28-J-Im18-76****\n",
      "****Processing liukesheng-J-Im30-99****\n",
      "****Processing lixueyong-J-Im25-31****\n",
      "****Processing lizhongliang-J-Im19-86****\n",
      "****Processing loulinhua-S-Im27-30****\n",
      "****Processing lufeng-J-Im28-103****\n",
      "****Processing luojun-J-Im22-81****\n",
      "****Processing luoyunshen-J-Im29-94****\n",
      "****Processing lvshibiao-J-Im20-76****\n",
      "****Processing maliwei-S-Im30-48-J-Im30-101****\n",
      "****Processing miqiurao-S-Im22-34--J-Im22-85****\n",
      "****Processing niyongru-S-Im38-43-J-Im38-148****\n",
      "****Processing panbanggeng-J-Im19-78****\n",
      "****Processing panhejian-J-Im39-57****\n",
      "****Processing panzhangsong-J-Im26-91****\n",
      "****Processing pengzhengjiang-J-Im38-160****\n",
      "****Processing qianfuying-J-Im20-87****\n",
      "****Processing qiuzhidong-J-Im25-42****\n",
      "****Processing renjiasheng-J-Im26-88****\n",
      "****Processing ruweiping-S-Im52-63-J-Im52-94****\n",
      "****Processing shenglina-J-Im21-65****\n",
      "****Processing shenliqiang-J-Im29-137****\n",
      "****Processing shenwenjiao-S-Im24-35****\n",
      "****Processing shenxuefu-S-Im33-40-J-Im33-101****\n",
      "****Processing shenyangfeng-J-Im36-120****\n",
      "****Processing shiguohu-J-Im19-70****\n",
      "****Processing shijiuwei-J-Im29-130****\n",
      "****Processing shujianqiang-S-Im22-30-J-Im22-59****\n",
      "****Processing sishouzhong-J-Im25-137****\n",
      "****Processing sizhongyu-J-Im22-81****\n",
      "****Processing sunlibing-J-Im24-82****\n",
      "****Processing sunyudong-J-Im37-95****\n",
      "****Processing tangguoliang-J-Im18-41****\n",
      "****Processing tonghuiling-J-Im22-78****\n",
      "****Processing tongjinglin-J-Im36-146****\n",
      "****Processing wangchenrong-S-Im18-24-J-Im18-38****\n",
      "****Processing wangjiangang-J-Im23-60****\n",
      "****Processing wangjiangwei-J-Im37-143****\n",
      "****Processing wangweibo-J-Im36-149****\n",
      "****Processing wangxinchun-J-Im18-81****\n",
      "****Processing wangyaotang-J-Im31-100****\n",
      "****Processing wangyefu-J-Im42-112****\n",
      "****Processing wangyonghui-S-Im18-27-J-Im18-84****\n",
      "****Processing wangzhuxi-J-Im25-144****\n",
      "****Processing weiguanxin-J-Im43-116****\n",
      "****Processing weinaichao-J-Im59-162****\n",
      "****Processing weizhiqing-J-Im33-45****\n",
      "****Processing wenyongguo-J-Im23-121****\n",
      "****Processing wujufen-J-Im31-135****\n",
      "****Processing wuwanglong-J-Im31-125****\n",
      "****Processing wuxiangyang-S-Im18-25****\n",
      "****Processing wuyingbo-J-Im36-98****\n",
      "****Processing wuyueming-J-Im36-138****\n",
      "****Processing xiaminsong-S-Im40-51-J-Im40-139****\n",
      "****Processing xiayunqing-J-Im33-141****\n",
      "****Processing xiechangyou-S-Im22-31-J-Im22-84****\n",
      "****Processing xuanhuili-J-Im30-135****\n",
      "****Processing xuhong-S-Im23-38-J-Im23-40****\n",
      "****Processing xushangfa-J-Im36-141****\n",
      "****Processing xuyanfang-J-Im20-80****\n",
      "****Processing xuyaofeng-J-Im24-119****\n",
      "****Processing yangbaozhi-J-Im27-65****\n",
      "****Processing yangbingshui-S-Im25-33-J-Im25-56****\n",
      "****Processing yangdongshui-S-Im15-21****\n",
      "****Processing yanglanfen-S-Im19-33****\n",
      "****Processing yangmin-J-Im37-150****\n",
      "****Processing yangxiufu-S-Im25-37-J-Im25-29****\n",
      "****Processing yangxuehua-J-Im23-79****\n",
      "****Processing yangyulin-J-Im16-58****\n",
      "****Processing yangzhanxiang-J-Im31-145****\n",
      "****Processing yangzhengfu-S-Im16-30-J-Im16-77****\n",
      "****Processing yaocaiming-J-Im26-88****\n",
      "****Processing yaojianmin-S-Im20-29-J-Im20-86****\n",
      "****Processing yaoliumei-S-Im28-39****\n",
      "****Processing yepeng-J-Im26-125****\n",
      "****Processing yewenyi-J-Im36-130****\n",
      "****Processing yexiyou-S-Im19-27-J-Im19-62****\n",
      "****Processing yingguoliang-J-Im55-130****\n",
      "****Processing yingmeiqi-S-Im22-25-J-Im16-36****\n",
      "****Processing yinshixiu-S-Im23-25-J-Im23-79****\n",
      "****Processing yintianxing-J-Im24-38****\n",
      "****Processing yinyuanyuan-J-Im20-78****\n",
      "****Processing yuanlinyue-J-Im27-120****\n",
      "****Processing yugenrong-J-Im18-60****\n",
      "****Processing yuhongliang-S-Im26-37-J-Im26-105****\n",
      "****Processing yujiada-J-Im21-48****\n",
      "****Processing yujinfang-J-Im31-106****\n",
      "****Processing yulinhang-J-Im14-57****\n",
      "****Processing yuyunguo-J-Im12-15****\n",
      "****Processing zengjun-J-Im22-57****\n",
      "****Processing zhangboqian-S-Im22-32-J-Im22-88****\n",
      "****Processing zhangchaodong-J-Im20-80****\n",
      "****Processing zhangguangming-J-21-138****\n",
      "****Processing zhanghaitao-S-Im25-49-J-Im25-145****\n",
      "****Processing zhanglimin-J-Im40-149****\n",
      "****Processing zhangshenxiang-J-Im41-83****\n",
      "****Processing zhangshiliang-J-Im32-49****\n",
      "****Processing zhangyide-J-Im28-107****\n",
      "****Processing zhangying-S-Im29-44****\n",
      "****Processing zhangzhefang-S-Im22-31-J-Im22-59****\n",
      "****Processing zhaodaqing-J-Im12-68****\n",
      "****Processing zhaowenxian-J-Im43-111****\n",
      "****Processing zhengjiyou-J-Im28-136****\n",
      "****Processing zhenhui-J-Im28-101****\n",
      "****Processing zhoufengnian-J-Im24-121****\n",
      "****Processing zhouguoyang-J-Im31-96****\n",
      "****Processing zhourongjie-S-Im19-27-J-Im19-64****\n",
      "****Processing zhousuhua-J-Im25-96****\n",
      "****Processing zhouyingnan-J-Im47-125****\n",
      "****Processing zhujunfei-J-Im24-88****\n",
      "****Processing zhuseng-S-Im24-31-J-Im24-105****\n",
      "****Processing zhuxutao-J-Im23-78****\n",
      "****Processing zhuyongfu-J-Im22-80****\n",
      "****Processing zhuyuejin-J-Im21-72****\n",
      "****Processing baozuoshi-J-16-79****\n",
      "****Processing changzhenxuan-J-15-55****\n",
      "****Processing chenaijiao-J-26-41****\n",
      "****Processing chencaiying-J-19-79****\n",
      "****Processing chenfuliang-S-21-31-J-21-84****\n",
      "****Processing chenganyao-J-19-40****\n",
      "****Processing chenhui-S-17-25-J-17-87****\n",
      "****Processing chenjufa-J-16-66****\n",
      "****Processing digenlan-J-23-50****\n",
      "****Processing fangchunfeng-J-16-48****\n",
      "****Processing fangzhuxiang-J-18-61****\n",
      "****Processing fudehe-S-20-33-J-20-70****\n",
      "****Processing ganxiaobin-J-23-51****\n",
      "****Processing huangwanman-S-15-30****\n",
      "****Processing kongxiaoqing-S-19-32-J-27-94****\n",
      "****Processing liangjianjun-S-17-23****\n",
      "****Processing linfaqiu-S-18-29****\n",
      "****Processing linjiaxiang-J-21-72****\n",
      "****Processing linrichun-J-16-72****\n",
      "****Processing lirucou-J-19-59****\n",
      "****Processing liubihai-S-23-26-J-23-93****\n",
      "****Processing liuhongfu-J-57-200****\n",
      "****Processing liuzhangliu-J-22-28****\n",
      "****Processing nixueya-J-19-75****\n",
      "****Processing pancunxiao-S-16-30-J-16-70****\n",
      "****Processing shanghongjun-J-22-84****\n",
      "****Processing shenjian-J-15-81****\n",
      "****Processing siyoulin-S-16-26****\n",
      "****Processing sunhongliang-S-23-34****\n",
      "****Processing wangjicheng-J-14-22****\n",
      "****Processing wangxiaofu-S-19-29-J-19-65****\n",
      "****Processing xiafangzhou-S-18-25-J-18-80****\n",
      "****Processing xiangweiwen-J-25-52****\n",
      "****Processing xucaixiang-J-17-36****\n",
      "****Processing xuhangying-J-25-63****\n",
      "****Processing xuheping-S-19-35-J-19-70****\n",
      "****Processing xujiahua-S-20-33-J-20-71****\n",
      "****Processing xupinglun-S-18-28-J-18-32****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****Processing yejiangen-J-15-34****\n",
      "****Processing yuguiying-S-16-22-J-16-77****\n",
      "****Processing yujunying-J-15-82****\n",
      "****Processing zhangjiahua-J-19-78****\n",
      "****Processing zhangjianliang-J-16-77****\n",
      "****Processing zhangping-J-25-88****\n",
      "****Processing zhengchong-S-16-31-J-16-87****\n",
      "****Processing zhongchuankun-J-17-69****\n",
      "****Processing zhoujianglong-S-17-31****\n",
      "****Processing zhuxinjian-J-20-23****\n",
      "****Processing baochunsheng-J-20-82****\n",
      "****Processing baojinan-J-24-87****\n",
      "****Processing chengyonghui-J-17-81****\n",
      "****Processing chenjiandong-S-19-28-J-19-91****\n",
      "****Processing chensiqi-S-17-28-J-17-69****\n",
      "****Processing dukun-S-20-22-J-20-23****\n",
      "****Processing fanghongwei-J-22-71****\n",
      "****Processing fangyuxian-J-23-60****\n",
      "****Processing guoyinhua-J-13-87****\n",
      "****Processing heguangfa-J-27-88****\n",
      "****Processing huanglijun-J-24-98****\n",
      "****Processing jinchongfei-J-22-92****\n",
      "****Processing liguangjun-S-25-31-J-25-93****\n",
      "****Processing liguirong-S-18-22****\n",
      "****Processing linkegui-S-18-33-J-18-54****\n",
      "****Processing lisiquan-S-68-70-J-68-89****\n",
      "****Processing liubingsong-J-20-84****\n",
      "****Processing liudongxian-J-16-66****\n",
      "****Processing liushufen-S-18-27-J-18-78****\n",
      "****Processing luohongzhang-J-17-41****\n",
      "****Processing panhualin-S-24-29****\n",
      "****Processing pengshihong-J-23-53****\n",
      "****Processing qiansongbo-J-19-24****\n",
      "****Processing shanlegen-S-22-30-J-22-79****\n",
      "****Processing shiaihong-J-36-80****\n",
      "****Processing sunhongbin-J-19-66****\n",
      "****Processing tanjiarong-S-17-23****\n",
      "****Processing tongyunbao-J-18-69****\n",
      "****Processing wangliqiang-J-20-86****\n",
      "****Processing wangqing-J-35-102****\n",
      "****Processing wangqiyuan-J-16-62****\n",
      "****Processing wangzhengjin-J-16-82****\n",
      "****Processing xiashubiao-J-24-88****\n",
      "****Processing xingxiangjuan-J-20-76****\n",
      "****Processing xumeijuan-J-16-66****\n",
      "****Processing xuweiliang-S-22-25-J-22-74****\n",
      "****Processing xuxingzheng-J-16-63****\n",
      "****Processing xuyongbiao-J-18-67****\n",
      "****Processing xuzhaofang-S-21-26-J-21-86****\n",
      "****Processing yangmingjun-S-15-24-J-15-61****\n",
      "****Processing yaowenhao-J-36-47****\n",
      "****Processing yexianchang-S-17-30-J-17-74****\n",
      "****Processing yuguiji-S-31-33****\n",
      "****Processing yuguoping-J-19-35****\n",
      "****Processing zhangjian-J-26-89****\n",
      "****Processing zhangmaoxiang-S-25-34****\n",
      "****Processing zhangshiqin-J-15-22****\n",
      "****Processing zhangwei-S-20-26-J-20-61****\n",
      "****Processing zhangwenzhong-J-16-68****\n",
      "****Processing zhangxueqiao-S-26-31****\n",
      "****Processing zhengguozheng-J-18-81****\n",
      "****Processing zhouweigui-J-21-80****\n",
      "****Processing 俞沧子-S-82-89-J-82-258****\n",
      "****Processing 傅阿乔-S-69-115-J-96-257****\n",
      "****Processing 卢承流-J-79-350****\n",
      "****Processing 叶超涵-S-97-103-J-97-323****\n",
      "****Processing 姜浩芳-S-63-118-J-63-288****\n",
      "****Processing 孙建华-J-64-173****\n",
      "****Processing 张林生-J-75-237****\n",
      "****Processing 朱大波-J-23-179****\n",
      "****Processing 李资浩-S-41-68****\n",
      "****Processing 欧兆辉-J-59-245****\n",
      "****Processing 江西向-J-114-274****\n",
      "****Processing 蒋世良-S-47-101-J-47-312****\n",
      "****Processing 许建敏-J-102-397****\n",
      "****Processing 许杏琴-J-150-266****\n",
      "****Processing 赵晴-J-9-75****\n",
      "****Processing 陈志武-J-69-407****\n",
      "****Processing 韩桂英-J-92-143****\n",
      "****Processing 俞子珊-J-71-191****\n",
      "****Processing 刘培华-J-56-224****\n",
      "****Processing 姚群芳-J-70-141-J-160-192****\n",
      "****Processing 孙业武-S-100-164-J-100-306****\n",
      "****Processing 张信基-J-54-62****\n",
      "****Processing 慈能满-J-76-106****\n",
      "****Processing 章国林-J-82-180****\n",
      "****Processing 章群娣-S-59-81-J-59-73****\n",
      "****Processing 陈金财-J-69-226****\n",
      "****Processing 马康美-S-74-114-J-74-318****\n"
     ]
    }
   ],
   "source": [
    "# 将各个病例中的png图片文件夹统一移动到一起供yolov5检测, not_move=True表示若有labels则不移动去检测\n",
    "def move_together_for_detect(input_folder, dst_path, not_move=True):   \n",
    "    if not os.path.exists(dst_path):\n",
    "        os.mkdir(dst_path)\n",
    "    root_name = input_folder.split('/')[-1] if input_folder.split('/')[-1] != '' else input_folder.split('/')[-2]\n",
    "    dst_path = os.path.join(dst_path, root_name)\n",
    "\n",
    "    for patient in sorted(os.listdir(input_folder)):\n",
    "        if os.path.isfile(os.path.join(input_folder, patient)):\n",
    "            continue\n",
    "        if not_move and os.path.exists(os.path.join(input_folder, patient, '2', 'labels')) \\\n",
    "        and os.path.exists(os.path.join(input_folder, patient, '2', f'pred_images_{lower_b}_{upper_b}')):\n",
    "            continue\n",
    "        print(f'****Processing {patient}****')\n",
    "        name = patient #name = patient.split('-')[0]\n",
    "        if os.path.exists(os.path.join(dst_path, name)):\n",
    "            print(f\"\\tremove {os.path.join(dst_path, name)}\")\n",
    "            shutil.rmtree(os.path.join(dst_path, name))\n",
    "\n",
    "        try:\n",
    "            shutil.copytree(os.path.join(input_folder, patient, '2', f'images_{lower_b}_{upper_b}'), os.path.join(dst_path, name))\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "\n",
    "move_together_for_detect('/nfs3-p1/zsxm/dataset/2021-9-8/', '/nfs3-p1/zsxm/dataset/9_detect/')\n",
    "move_together_for_detect('/nfs3-p1/zsxm/dataset/2021-9-13/', '/nfs3-p1/zsxm/dataset/9_detect/')\n",
    "move_together_for_detect('/nfs3-p1/zsxm/dataset/2021-9-19/', '/nfs3-p1/zsxm/dataset/9_detect/')\n",
    "move_together_for_detect('/nfs3-p1/zsxm/dataset/2021-9-28/', '/nfs3-p1/zsxm/dataset/9_detect/')\n",
    "#move_together_for_detect('/nfs3-p2/zsxm/dataset/2021-10-19-aa/', '/nfs3-p1/zsxm/dataset/9_detect/')\n",
    "move_together_for_detect('/nfs3-p2/zsxm/dataset/2021-10-19-imh/', '/nfs3-p1/zsxm/dataset/9_detect/')\n",
    "#move_together_for_detect('/nfs3-p2/zsxm/dataset/2021-10-19-pau/', '/nfs3-p1/zsxm/dataset/9_detect/')\n",
    "move_together_for_detect('/nfs3-p2/zsxm/dataset/2021-11-20/', '/nfs3-p1/zsxm/dataset/9_detect/')\n",
    "move_together_for_detect('/nfs3-p2/zsxm/dataset/2021-11-20-imh/', '/nfs3-p1/zsxm/dataset/9_detect/')\n",
    "#move_together_for_detect('/nfs3-p2/zsxm/dataset/2021-11-20-pau/', '/nfs3-p1/zsxm/dataset/9_detect/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1761401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#将检测结果移动回原文件夹内\n",
    "def move_back(result_path, ori_path):\n",
    "    if not os.path.exists(result_path):\n",
    "        print(f'目录不存在：{result_path}')\n",
    "        return\n",
    "    for patient in sorted(os.listdir(result_path)):\n",
    "        print(f'Processing {patient}')\n",
    "        p_res_path = os.path.join(result_path, patient)\n",
    "        o_res_path = os.path.join(ori_path, patient, '2', f'pred_images_{lower_b}_{upper_b}')\n",
    "        if os.path.exists(o_res_path):\n",
    "            shutil.rmtree(o_res_path)\n",
    "        os.mkdir(o_res_path)\n",
    "        for file in os.listdir(p_res_path):\n",
    "            if os.path.isfile(os.path.join(p_res_path, file)):\n",
    "                shutil.move(os.path.join(p_res_path, file), os.path.join(o_res_path, file))\n",
    "            elif os.path.isdir(os.path.join(p_res_path, file)):\n",
    "                if os.path.exists(os.path.join(ori_path, patient, '2', file)):\n",
    "                    shutil.rmtree(os.path.join(ori_path, patient, '2', file))\n",
    "                shutil.move(os.path.join(p_res_path, file), os.path.join(ori_path, patient, '2', file))\n",
    "        os.rmdir(p_res_path)\n",
    "    os.rmdir(result_path)\n",
    "\n",
    "\n",
    "#move_back('/home/zsxm/pythonWorkspace/yolov5_old/runs/detect/2021-9-8', '/nfs3-p2/zsxm/dataset/2021-9-8/')\n",
    "move_back('/home/zsxm/pythonWorkspace/yolov5_old/runs/detect/2021-9-13', '/nfs3-p1/zsxm/dataset/2021-9-13/')\n",
    "move_back('/home/zsxm/pythonWorkspace/yolov5_old/runs/detect/2021-9-19', '/nfs3-p2/zsxm/dataset/2021-9-19/')\n",
    "move_back('/home/zsxm/pythonWorkspace/yolov5_old/runs/detect/2021-9-28', '/nfs3-p2/zsxm/dataset/2021-9-28/')\n",
    "#move_back('/home/zsxm/pythonWorkspace/yolov5_old/runs/detect/2021-10-19-imh', '/nfs3-p2/zsxm/dataset/2021-10-19-imh/')\n",
    "move_back('/home/zsxm/pythonWorkspace/yolov5_old/runs/detect/2021-11-20', '/nfs3-p1/zsxm/dataset/2021-11-20/')\n",
    "move_back('/home/zsxm/pythonWorkspace/yolov5_old/runs/detect/2021-11-20-imh', '/nfs3-p2/zsxm/dataset/2021-11-20-imh/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574510e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切出主动脉\n",
    "def find_coordinate(height, width, label_file, aorta):\n",
    "    with open(label_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    assert len(lines) <= 2, f'label.txt应该存储不多于2个label：{label_file.split(\"/\")[-1]}'\n",
    "    if len(lines) == 1:\n",
    "        assert aorta == 'j', f'如果只有一个label那么此时应为降主动脉, 但实际为{aorta}：{label_file.split(\"/\")[-1]}'\n",
    "        corr = list(map(lambda x: float(x), lines[0].split()))\n",
    "        x, y, w, h = corr[1], corr[2], corr[3], corr[4]\n",
    "        assert 0.25 < x < 0.75 and 0.15 < y < 0.85, f'边界框中心({x}, {y})出界：{label_file.split(\"/\")[-1]}'\n",
    "    else:\n",
    "        corr1, corr2 = list(map(lambda x: float(x), lines[0].split())), list(map(lambda x: float(x), lines[1].split()))\n",
    "        assert 0.25 < corr1[1] < 0.75 and 0.15 < corr1[2] < 0.85, f'边界框1中心({corr1[1]}, {corr1[2]})出界：{label_file.split(\"/\")[-1]}'\n",
    "        assert 0.25 < corr2[1] < 0.75 and 0.15 < corr2[2] < 0.85, f'边界框2中心({corr2[1]}, {corr2[2]})出界：{label_file.split(\"/\")[-1]}'\n",
    "        if aorta == 's':\n",
    "            x, y, w, h = (corr1[1], corr1[2], corr1[3], corr1[4]) if corr1[2] < corr2[2] else (corr2[1], corr2[2], corr2[3], corr2[4])\n",
    "        elif aorta == 'j':\n",
    "            x, y, w, h = (corr1[1], corr1[2], corr1[3], corr1[4]) if corr1[2] > corr2[2] else (corr2[1], corr2[2], corr2[3], corr2[4])\n",
    "        else:\n",
    "            raise Exception(f'aorta 应该为\"s\"或\"j\"其中之一: {label_file.split(\"/\")[-1]}')\n",
    "    w, h = int(width*w), int(height*h)\n",
    "    w, h = max(w, h), max(w, h)\n",
    "    return int(width*x-w/2), int(height*y-h/2), int(width*x+w/2+1), int(height*y+h/2+1)\n",
    "\n",
    "def crop_images(input_path, error_patient_list):\n",
    "    workbook_path = os.path.join(input_path, 'label.xlsx')\n",
    "    wb = openpyxl.load_workbook(workbook_path)\n",
    "    sheet = wb['Sheet1']\n",
    "    \n",
    "    for patient in sorted(os.listdir(input_path)):\n",
    "        if os.path.isfile(os.path.join(input_path, patient)):\n",
    "            continue\n",
    "        flag = True\n",
    "        for row in sheet.iter_rows():\n",
    "            if row[0].value == patient.split('-')[0]:\n",
    "                if row[3].value is not None and row[4].value is not None:\n",
    "                    flag = False\n",
    "                    pl = row[4].value.lower().split('-')\n",
    "                    plct = row[3].value.lower().split('-')\n",
    "                    assert len(pl) == len(plct), f'CT和CTA标签不等长{input_path}:{patient}, {len(pl)}, {len(plct)}'\n",
    "                break\n",
    "        if flag: continue\n",
    "        print(f'******Processing {patient}******')\n",
    "        image_path = os.path.join(input_path, patient, '2', f'images_{lower_b}_{upper_b}')\n",
    "        label_path = os.path.join(input_path, patient, '2', 'labels')\n",
    "        crop_path = os.path.join(input_path, patient, '2', f'crops_{lower_b}_{upper_b}')\n",
    "        if os.path.exists(crop_path):\n",
    "            shutil.rmtree(crop_path)\n",
    "        os.mkdir(crop_path)\n",
    "        \n",
    "        crop_flag = True\n",
    "        for i, s in enumerate(pl):\n",
    "            if s != 's' and s != 'j':\n",
    "                continue\n",
    "            start, end = int(pl[i+1])-1, int(pl[i+2])\n",
    "            for j in range(start, end):\n",
    "                img = Image.open(os.path.join(image_path, f'{patient}_{j:04d}.png'))\n",
    "                img = np.array(img)\n",
    "                try:\n",
    "                    x1, y1, x2, y2 = find_coordinate(*img.shape[0:2], os.path.join(label_path, f'{patient}_{j:04d}.txt'), s)\n",
    "                except:\n",
    "                    traceback.print_exc()\n",
    "                    crop_flag = False\n",
    "                else:#if crop_flag:\n",
    "                    crop = img[y1:y2, x1:x2]\n",
    "                    crop = Image.fromarray(crop)\n",
    "                    crop.save(os.path.join(crop_path, f'{patient}_{s}_{j:04d}.png'))\n",
    "        if not crop_flag:\n",
    "            error_patient_list.append(patient)\n",
    "\n",
    "epl1 = []\n",
    "\n",
    "crop_images('/nfs3-p1/zsxm/dataset/2021-9-8/', epl1)\n",
    "crop_images('/nfs3-p1/zsxm/dataset/2021-9-13/', epl1)\n",
    "crop_images('/nfs3-p1/zsxm/dataset/2021-9-19/', epl1)\n",
    "crop_images('/nfs3-p1/zsxm/dataset/2021-9-28/', epl1)\n",
    "crop_images('/nfs3-p1/zsxm/dataset/2021-10-19-imh/', epl1)\n",
    "crop_images('/nfs3-p1/zsxm/dataset/2021-11-20/', epl1)\n",
    "crop_images('/nfs3-p1/zsxm/dataset/2021-11-20-imh/', epl1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df154bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(epl1))\n",
    "print(epl1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5283cfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切出范围外冗余为3的主动脉\n",
    "def find_coordinate(height, width, label_file, aorta):\n",
    "    with open(label_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    assert len(lines) <= 2, f'label.txt应该存储不多于2个label：{label_file.split(\"/\")[-1]}'\n",
    "    if len(lines) == 1:\n",
    "        assert aorta == 'j', f'如果只有一个label那么此时应为降主动脉, 但实际为{aorta}：{label_file.split(\"/\")[-1]}'\n",
    "        corr = list(map(lambda x: float(x), lines[0].split()))\n",
    "        x, y, w, h = corr[1], corr[2], corr[3], corr[4]\n",
    "        assert 0.25 < x < 0.75 and 0.2 < y < 0.8, f'边界框中心({x}, {y})出界：{label_file.split(\"/\")[-1]}'\n",
    "    else:\n",
    "        corr1, corr2 = list(map(lambda x: float(x), lines[0].split())), list(map(lambda x: float(x), lines[1].split()))\n",
    "        assert 0.25 < corr1[1] < 0.75 and 0.2 < corr1[2] < 0.8, f'边界框1中心({corr1[1]}, {corr1[2]})出界：{label_file.split(\"/\")[-1]}'\n",
    "        assert 0.25 < corr2[1] < 0.75 and 0.2 < corr2[2] < 0.8, f'边界框2中心({corr2[1]}, {corr2[2]})出界：{label_file.split(\"/\")[-1]}'\n",
    "        if aorta == 's':\n",
    "            x, y, w, h = (corr1[1], corr1[2], corr1[3], corr1[4]) if corr1[2] < corr2[2] else (corr2[1], corr2[2], corr2[3], corr2[4])\n",
    "        elif aorta == 'j':\n",
    "            x, y, w, h = (corr1[1], corr1[2], corr1[3], corr1[4]) if corr1[2] > corr2[2] else (corr2[1], corr2[2], corr2[3], corr2[4])\n",
    "        else:\n",
    "            raise Exception(f'aorta 应该为\"s\"或\"j\"其中之一: {label_file.split(\"/\")[-1]}')\n",
    "    w, h = int(width*w), int(height*h)\n",
    "    w, h = max(w, h), max(w, h)\n",
    "    return int(width*x-w/2), int(height*y-h/2), int(width*x+w/2+1), int(height*y+h/2+1)\n",
    "\n",
    "def crop_images(input_path, error_patient_list):\n",
    "    workbook_path = os.path.join(input_path, 'label.xlsx')\n",
    "    wb = openpyxl.load_workbook(workbook_path)\n",
    "    sheet = wb['Sheet1']\n",
    "    \n",
    "    for patient in sorted(os.listdir(input_path)):\n",
    "        if os.path.isfile(os.path.join(input_path, patient)):\n",
    "            continue\n",
    "        flag = True\n",
    "        for row in sheet.iter_rows():\n",
    "            if row[0].value == patient.split('-')[0]:\n",
    "                if row[3].value is not None and row[4].value is not None:\n",
    "                    flag = False\n",
    "                    pl = row[4].value.lower().split('-')\n",
    "                    plct = row[3].value.lower().split('-')\n",
    "                    assert len(pl) == len(plct), f'CT和CTA标签不等长{input_path}:{patient}, {len(pl)}, {len(plct)}'\n",
    "                break\n",
    "        if flag: continue\n",
    "        \n",
    "        print(f'******Processing {patient}******')\n",
    "        image_path = os.path.join(input_path, patient, '2', f'images_{lower_b}_{upper_b}')\n",
    "        label_path = os.path.join(input_path, patient, '2', 'labels')\n",
    "        crop_path = os.path.join(input_path, patient, '2', f'crops_{lower_b}_{upper_b}')\n",
    "        if os.path.exists(crop_path):\n",
    "            shutil.rmtree(crop_path)\n",
    "        os.mkdir(crop_path)\n",
    "        \n",
    "        crop_flag = True\n",
    "        for i, s in enumerate(pl):\n",
    "            if s != 's' and s != 'j':\n",
    "                continue\n",
    "            start, end = int(pl[i+1])-1, int(pl[i+2])\n",
    "            for j in range(start-3, end+3):\n",
    "                try:\n",
    "                    img = Image.open(os.path.join(image_path, f'{patient}_{j:04d}.png'))\n",
    "                    img = np.array(img)\n",
    "                    x1, y1, x2, y2 = find_coordinate(*img.shape[0:2], os.path.join(label_path, f'{patient}_{j:04d}.txt'), s)\n",
    "                except:\n",
    "                    traceback.print_exc()\n",
    "                    crop_flag = False\n",
    "                else:#if crop_flag:\n",
    "                    crop = img[y1:y2, x1:x2]\n",
    "                    crop = Image.fromarray(crop)\n",
    "                    if start <= j < end:\n",
    "                        crop.save(os.path.join(crop_path, f'{patient}_{s}_{j:04d}.png'))\n",
    "                    else:\n",
    "                        crop.save(os.path.join(crop_path, f'{patient}_{s}_{j:04d}_n.png'))\n",
    "        if not crop_flag:\n",
    "            #print('Delete crop_path')\n",
    "            #shutil.rmtree(crop_path)\n",
    "            error_patient_list.append(patient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a08fa9d",
   "metadata": {},
   "source": [
    "# 3.复制文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "943572f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_path = f'/nfs3-p2/zsxm/dataset/aorta_classify_cta_{lower_b}_{upper_b}'\n",
    "os.makedirs(classify_path, exist_ok=True)\n",
    "for dataset in ['train', 'val']:\n",
    "    dst_path = os.path.join(classify_path, dataset)\n",
    "    os.makedirs(dst_path, exist_ok=True)\n",
    "    for cate in range(3):\n",
    "        cls_path = os.path.join(dst_path, str(cate))\n",
    "        os.makedirs(cls_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "370d1c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = set()\n",
    "val_set = set()\n",
    "ct_path = f'/nfs3-p2/zsxm/dataset/aorta_classify_ct_{lower_b}_{upper_b}/'\n",
    "for cate in os.listdir(os.path.join(ct_path, 'train')):\n",
    "    for img in os.listdir(os.path.join(ct_path, 'train', cate)):\n",
    "        train_set.add(img.split('_')[0])\n",
    "for img in os.listdir(os.path.join(ct_path, 'val')):\n",
    "    for img in os.listdir(os.path.join(ct_path, 'val', cate)):\n",
    "        val_set.add(img.split('_')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acb97424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785 74\n"
     ]
    }
   ],
   "source": [
    "print(len(train_set), len(val_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28706a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_cta(input_path, cate, train_set, val_set):\n",
    "    workbook_path = os.path.join(input_path, 'label.xlsx')\n",
    "    wb = openpyxl.load_workbook(workbook_path)\n",
    "    sheet = wb['Sheet1']\n",
    "    \n",
    "    for patient in sorted(os.listdir(input_path)):\n",
    "        if os.path.isfile(os.path.join(input_path, patient)):\n",
    "            continue\n",
    "        flag = True\n",
    "        for row in sheet.iter_rows():\n",
    "            if row[0].value == patient.split('-')[0]:\n",
    "                if row[3].value is not None and row[4].value is not None:\n",
    "                    flag = False\n",
    "                break\n",
    "        if flag: continue\n",
    "        print(f'******Processing {patient}******')\n",
    "        if patient in train_set:\n",
    "            dst_path = os.path.join(classify_path, 'train', str(cate))\n",
    "        elif patient in val_set:\n",
    "            dst_path = os.path.join(classify_path, 'val', str(cate))\n",
    "        else:\n",
    "            raise Exception(f'{patient} neither in train_set nor in val_set')\n",
    "        ori_path = os.path.join(input_path, patient, '2', f'crops_{lower_b}_{upper_b}')\n",
    "        for img in os.listdir(ori_path):\n",
    "            shutil.copy(os.path.join(ori_path, img), os.path.join(dst_path, img))\n",
    "            \n",
    "\n",
    "move_cta('/nfs3-p1/zsxm/dataset/2021-9-17-negative/', train_set, val_set, 0)\n",
    "move_cta('/nfs3-p1/zsxm/dataset/2021-9-29-negative/', train_set, val_set, 0)\n",
    "move_cta('/nfs3-p1/zsxm/dataset/2021-9-8/', train_set, val_set, 1)\n",
    "move_cta('/nfs3-p1/zsxm/dataset/2021-9-13/', train_set, val_set, 1)\n",
    "move_cta('/nfs3-p1/zsxm/dataset/2021-9-19/', train_set, val_set, 1)\n",
    "move_cta('/nfs3-p1/zsxm/dataset/2021-9-28/', train_set, val_set, 1)\n",
    "move_cta('/nfs3-p1/zsxm/dataset/2021-10-19-imh/', train_set, val_set, 2)\n",
    "move_cta('/nfs3-p1/zsxm/dataset/2021-11-20/', train_set, val_set, 1)\n",
    "move_cta('/nfs3-p1/zsxm/dataset/2021-11-20-imh/', train_set, val_set, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
