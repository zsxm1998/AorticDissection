{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c71f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from train import create_net\n",
    "from utils import transforms as MT\n",
    "from utils.datasets import AortaDataset3DCenter\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(63910)\n",
    "torch.manual_seed(53152)\n",
    "torch.cuda.manual_seed_all(7987)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720867ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels, n_classes, batch_size = 1, 4, 128\n",
    "\n",
    "transform = T.Compose([\n",
    "    MT.Resize3D(81),\n",
    "    MT.CenterCrop3D(81),\n",
    "    MT.ToTensor3D(),\n",
    "])\n",
    "\n",
    "train = AortaDataset3DCenter('/nfs3-p1/zsxm/dataset/aorta_classify_ct_-100_500/center/train/', transform=transform, depth=7)\n",
    "val = AortaDataset3DCenter('/nfs3-p1/zsxm/dataset/aorta_classify_ct_-100_500/center/val/', transform=transform, depth=7)\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True, drop_last=False)\n",
    "val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb6ee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels, n_classes, batch_size = 1, 4, 128\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize(81), # 缩放图片(Image)，保持长宽比不变，最短边为img_size像素\n",
    "    T.CenterCrop(81), # 从图片中间切出img_size*img_size的图片\n",
    "    T.ToTensor(), # 将图片(Image)转成Tensor，归一化至[0, 1]\n",
    "])\n",
    "\n",
    "train = ImageFolder('/nfs3-p1/zsxm/dataset/aorta_classify_ct_-100_500/train/', transform=transform, loader=lambda path: Image.open(path))\n",
    "val = ImageFolder('/nfs3-p1/zsxm/dataset/aorta_classify_ct_-100_500/val/', transform=transform, loader=lambda path: Image.open(path))\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True, drop_last=False)\n",
    "val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a227950f",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = create_net(device, 'resnet', 34, n_channels, n_classes, '/nfs3-p2/zsxm/temp_path/single81.pth', entire=True, flag_3d=False)\n",
    "net.eval()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fdc9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HookModule:\n",
    "    def __init__(self, model, module):\n",
    "        self.model = model\n",
    "        self.handle = module.register_forward_hook(self._get_output)\n",
    "        \n",
    "    def _get_output(self, module, inputs, outputs):\n",
    "        self.outputs = outputs\n",
    "    \n",
    "    def grads(self, outputs, retain_graph=True, create_graph=True):\n",
    "        grads = torch.autograd.grad(outputs=outputs, inputs=self.outputs, retain_graph=retain_graph, create_graph=create_graph)\n",
    "        self.model.zero_grad()\n",
    "        print(grads[0].shape)\n",
    "        return grads[0]\n",
    "    \n",
    "    def remove(self):\n",
    "        self.handle.remove()\n",
    "        \n",
    "hook = HookModule(net, net.encoder.layer2[3].conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7129adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b514df5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grads(dataset, dataloader, end=500, start=0):\n",
    "    idx = 0\n",
    "    score_list = [[] for _ in range(n_classes)]\n",
    "    err_list = [[] for _ in range(n_classes)]\n",
    "    for imgs, true_categories in tqdm(dataloader, total=len(dataloader), desc='Dataset', unit='batch', leave=False):\n",
    "        imgs = imgs.to(device=device, dtype=torch.float32)\n",
    "        true_categories = true_categories.to(device=device, dtype=torch.long)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            categories_pred = torch.softmax(net(imgs), dim=1)\n",
    "            labels_pred = categories_pred.argmax(dim=1)\n",
    "            for i in range(len(true_categories)):\n",
    "                if labels_pred[i] == true_categories[i]:\n",
    "                    score_list[true_categories[i].item()].append((categories_pred[i, labels_pred[i]].item(), idx))\n",
    "                else:\n",
    "                    #err_list[true_categories[i].item()].append(dataset.samples[idx][0])\n",
    "                    pass\n",
    "                idx += 1\n",
    "    \n",
    "    grad_list = []\n",
    "    mask_list = []\n",
    "    for i in range(n_classes):\n",
    "        print(len(score_list[i]))\n",
    "        score_list[i].sort(key=lambda x: x[0], reverse=True)\n",
    "        print(score_list[i][end-1])\n",
    "        idx_list = [score[1] for score in score_list[i][start: end]]\n",
    "        tensor_list = []\n",
    "        for idx in idx_list:\n",
    "            tensor_list.append(dataset[idx][0])\n",
    "        batch = torch.stack(tensor_list, dim=0)\n",
    "        pred = net(batch.to(device))\n",
    "        nll_loss = F.nll_loss(pred, (torch.ones(batch.size(0))*i).to(device, dtype=torch.long))\n",
    "        grads = hook.grads(-nll_loss, True, False)\n",
    "        nll_loss.backward()\n",
    "        #grads = grads.abs().sum(dim=(2,3,4)).mean(dim=0)\n",
    "        grads = F.relu(grads).sum(dim=(2,3)).mean(dim=0)\n",
    "        print(grads.shape)\n",
    "        grad_list.append(grads.cpu().numpy())\n",
    "        mask = (grads>grads.mean()).long()\n",
    "        mask_list.append(mask.cpu().numpy())\n",
    "\n",
    "    grads = np.array(grad_list)\n",
    "    masks = np.array(mask_list)\n",
    "    return grads, masks, err_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1672b604",
   "metadata": {},
   "outputs": [],
   "source": [
    "grads, masks, err_list = get_grads(train, train_loader, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587d828a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(n_classes):\n",
    "#     print(len(err_list[i]))\n",
    "#     outpath = os.path.join('/nfs3-p2/zsxm/dataset/aorta_classify_ct_-100_500/err_imgs', str(i))\n",
    "#     os.makedirs(outpath, exist_ok=True)\n",
    "#     for img in err_list[i]:\n",
    "#         shutil.copy(img, os.path.join(outpath, img.split('/')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746a9305",
   "metadata": {},
   "outputs": [],
   "source": [
    "hm = grads - np.min(grads)\n",
    "hm = hm / np.max(hm)\n",
    "print(hm)\n",
    "\n",
    "def view_grads(grads, fig_w, fig_h, fig_path='./heatmap.png'):\n",
    "    f, ax = plt.subplots(figsize=(fig_w, fig_h), ncols=1)\n",
    "    ax.set_xlabel('convolutional kernel')\n",
    "    ax.set_ylabel('category')\n",
    "    sns.heatmap(grads, annot=False, ax=ax)\n",
    "    plt.savefig(fig_path, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    #plt.clf()\n",
    "    \n",
    "view_grads(hm, 30, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fde2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_grads(masks, 30, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c874cc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/nfs3-p2/zsxm/temp_path/pos_layer2_conv2.npy', masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9d3026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d555ce0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e4475a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4424ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (1,2,3)\n",
    "x, y, z = a\n",
    "print(x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac33578",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdNoise:\n",
    "    def __init__(self, model, module):\n",
    "        self.model = model\n",
    "        self.handle = module.register_forward_hook(self._get_output)\n",
    "        \n",
    "    def _get_output(self, module, inputs, outputs):\n",
    "        self.outputs = outputs\n",
    "        outputs += torch.randn(outputs.shape).to(outputs.device)\n",
    "    \n",
    "    def grads(self, outputs, retain_graph=True, create_graph=True):\n",
    "        grads = torch.autograd.grad(outputs=outputs, inputs=self.outputs, retain_graph=retain_graph, create_graph=create_graph)\n",
    "        self.model.zero_grad()\n",
    "        return grads[0]\n",
    "    \n",
    "    def remove(self):\n",
    "        self.handle.remove()\n",
    "        \n",
    "class Mul2:\n",
    "    def __init__(self, model, module):\n",
    "        self.model = model\n",
    "        self.handle = module.register_forward_hook(self._get_output)\n",
    "        \n",
    "    def _get_output(self, module, inputs, outputs):\n",
    "        self.outputs = outputs\n",
    "        outputs *= 2\n",
    "    \n",
    "    def grads(self, outputs, retain_graph=True, create_graph=True):\n",
    "        grads = torch.autograd.grad(outputs=outputs, inputs=self.outputs, retain_graph=retain_graph, create_graph=create_graph)\n",
    "        self.model.zero_grad()\n",
    "        return grads[0]\n",
    "    \n",
    "    def remove(self):\n",
    "        self.handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaca03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, 3)\n",
    "        self.conv2 = nn.Conv2d(10, 1, 3)\n",
    "        nn.init.constant_(self.conv1.weight, 1)\n",
    "        nn.init.constant_(self.conv1.weight, 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.exp(x)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "    \n",
    "test = Test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61be5db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2 = Mul2(test, test.conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f60a4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d18b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hn = AdNoise(test, test.conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde72e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hn.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd19cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(2,3,6,6)\n",
    "res = test(a)\n",
    "ressum = res.sum()\n",
    "print(res)\n",
    "print(ressum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dcbc7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(h2.outputs)\n",
    "print(h2.grads(ressum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75eeb14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(h2.outputs)\n",
    "print(h2.grads(ressum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dec6c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hn.outputs)\n",
    "print(hn.grads(ressum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e807ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.ones(2,2)\n",
    "print(id(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa45b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "t += 1\n",
    "print(id(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a051441",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = t+1\n",
    "print(id(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51f2db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "b = a\n",
    "print(id(a), id(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de26836c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bad_append(new_item, a_list=[]):\n",
    " \n",
    "    a_list.append(new_item)\n",
    " \n",
    "    return a_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda63d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bad_append(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121d1abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (1,2)\n",
    "a[0] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a3334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test():\n",
    "    a = None\n",
    "    \n",
    "def fun(x):\n",
    "    x = Test()\n",
    "    x.a = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811476e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t, k = Test(), Test()\n",
    "t.a = 1\n",
    "k.a = 2\n",
    "p = t\n",
    "print(p.a, t.a, k.a)\n",
    "print(id(p), id(t), id(k))\n",
    "p = k\n",
    "print(p.a, t.a, k.a)\n",
    "print(id(p), id(t), id(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa4e7c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
