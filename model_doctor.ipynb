{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c71f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from train import create_net\n",
    "from utils import transforms as MT\n",
    "from utils.datasets import AortaDataset3DCenter\n",
    "from utils.eval import eval_net\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(63910)\n",
    "torch.manual_seed(53152)\n",
    "torch.cuda.manual_seed_all(7987)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720867ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3D数据集\n",
    "n_channels, n_classes, batch_size = 2, 3, 128\n",
    "\n",
    "transform = T.Compose([\n",
    "    MT.Resize3D(81),\n",
    "    MT.CenterCrop3D(81),\n",
    "    MT.ToTensor3D(),\n",
    "    MT.SobelChannel(3, flag_3d=True),\n",
    "])\n",
    "\n",
    "train = AortaDataset3DCenter('/nfs3-p1/zsxm/dataset/aorta_classify_ct_-100_500/center/train/', transform=transform, depth=7)\n",
    "val = AortaDataset3DCenter('/nfs3-p1/zsxm/dataset/aorta_classify_ct_-100_500/center/val/', transform=transform, depth=7)\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True, drop_last=False)\n",
    "val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb6ee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2D数据集\n",
    "n_channels, n_classes, batch_size = 2, 3, 128\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize(81),\n",
    "    T.CenterCrop(81),\n",
    "    T.ToTensor(),\n",
    "    MT.SobelChannel(3, False),\n",
    "])\n",
    "\n",
    "train = ImageFolder('/nfs3-p1/zsxm/dataset/aorta_classify_ct_-100_500/train/', transform=transform, loader=lambda path: Image.open(path))\n",
    "val = ImageFolder('/nfs3-p1/zsxm/dataset/aorta_classify_ct_-100_500/val/', transform=transform, loader=lambda path: Image.open(path))\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True, drop_last=False)\n",
    "val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a227950f",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = create_net(device, 'resnet', 34, n_channels, n_classes, 'details/checkpoints/CrossEntropy/02-24_10:17:21/Net_best.pth', entire=True, flag_3d=True)\n",
    "net.eval()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e31f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fdc9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HookModule:\n",
    "    def __init__(self, model, module):\n",
    "        self.model = model\n",
    "        self.handle = module.register_forward_hook(self._get_output)\n",
    "        \n",
    "    def _get_output(self, module, inputs, outputs):\n",
    "        self.outputs = outputs\n",
    "    \n",
    "    def grads(self, outputs, retain_graph=True, create_graph=True):\n",
    "        grads = torch.autograd.grad(outputs=outputs, inputs=self.outputs, retain_graph=retain_graph, create_graph=create_graph)\n",
    "        self.model.zero_grad()\n",
    "        print(grads[0].shape)\n",
    "        return grads[0]\n",
    "    \n",
    "    def remove(self):\n",
    "        self.handle.remove()\n",
    "        \n",
    "hook = HookModule(net, net.encoder.layer4[2].conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7129adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b514df5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grads(dataset, dataloader, end=500, start=0):\n",
    "    idx = 0\n",
    "    score_list = [[] for _ in range(n_classes)]\n",
    "    err_list = [[] for _ in range(n_classes)]\n",
    "    for imgs, true_categories in tqdm(dataloader, total=len(dataloader), desc='Dataset', unit='batch', leave=False):\n",
    "        imgs = imgs.to(device=device, dtype=torch.float32)\n",
    "        true_categories = true_categories.to(device=device, dtype=torch.long)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            categories_pred = torch.softmax(net(imgs), dim=1)\n",
    "            labels_pred = categories_pred.argmax(dim=1)\n",
    "            for i in range(len(true_categories)):\n",
    "                if labels_pred[i] == true_categories[i]:\n",
    "                    score_list[true_categories[i].item()].append((categories_pred[i, labels_pred[i]].item(), idx))\n",
    "                else:\n",
    "                    #err_list[true_categories[i].item()].append(dataset.samples[idx][0])\n",
    "                    pass\n",
    "                idx += 1\n",
    "    \n",
    "    grad_list = []\n",
    "    mask_list = []\n",
    "    for i in range(n_classes):\n",
    "        print(len(score_list[i]))\n",
    "        score_list[i].sort(key=lambda x: x[0], reverse=True)\n",
    "        print(score_list[i][end-1])\n",
    "        idx_list = [score[1] for score in score_list[i][start: end]]\n",
    "        tensor_list = []\n",
    "        for idx in idx_list:\n",
    "            tensor_list.append(dataset[idx][0])\n",
    "        batch = torch.stack(tensor_list, dim=0)\n",
    "        pred = net(batch.to(device))\n",
    "        nll_loss = F.nll_loss(pred, (torch.ones(batch.size(0))*i).to(device, dtype=torch.long))\n",
    "        grads = hook.grads(-nll_loss, True, False)\n",
    "        nll_loss.backward()\n",
    "        grads = torch.abs(grads).sum(dim=(2,3,4)).mean(dim=0)#F.relu(grads).sum(dim=(2,3,4)).mean(dim=0)\n",
    "        #grads = F.relu(grads).sum(dim=(2,3)).mean(dim=0)\n",
    "        print(grads.shape)\n",
    "        grad_list.append(grads.cpu().numpy())\n",
    "        mask = (grads>grads.mean()).long()\n",
    "        mask_list.append(mask.cpu().numpy())\n",
    "\n",
    "    grads = np.array(grad_list)\n",
    "    masks = np.array(mask_list)\n",
    "    return grads, masks, err_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1672b604",
   "metadata": {},
   "outputs": [],
   "source": [
    "grads, masks, err_list = get_grads(train, train_loader, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587d828a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(n_classes):\n",
    "#     print(len(err_list[i]))\n",
    "#     outpath = os.path.join('/nfs3-p2/zsxm/dataset/aorta_classify_ct_-100_500/err_imgs', str(i))\n",
    "#     os.makedirs(outpath, exist_ok=True)\n",
    "#     for img in err_list[i]:\n",
    "#         shutil.copy(img, os.path.join(outpath, img.split('/')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746a9305",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hm = grads - np.min(grads)\n",
    "hm = hm / np.max(hm)\n",
    "print(hm)\n",
    "\n",
    "def view_grads(grads, fig_w, fig_h, fig_path='./heatmap.png'):\n",
    "    f, ax = plt.subplots(figsize=(fig_w, fig_h), ncols=1)\n",
    "    ax.set_xlabel('convolutional kernel')\n",
    "    ax.set_ylabel('category')\n",
    "    sns.heatmap(grads, annot=False, ax=ax)\n",
    "    plt.savefig(fig_path, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    #plt.clf()\n",
    "    \n",
    "view_grads(hm, 30, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fde2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_grads(masks, 30, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c874cc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/nfs3-p2/zsxm/ModelDoctor/3d_conv2_sobel_abs.npy', masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d555ce0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdc0f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_net(net, val_loader, len(val), device, final=True, PR_curve_save_dir='./')\n",
    "net.eval()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedcda8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForwardDoctor:\n",
    "    def __init__(self, model, module):\n",
    "        self.model = model\n",
    "        self.handle = module.register_forward_hook(self._modify_output)\n",
    "        \n",
    "    def _modify_output(self, module, inputs, outputs):\n",
    "        channel_sum = outputs.sum(dim=(2,3), keepdim=True) #[batch_size, channel, 1, 1]\n",
    "        channel_mean = channel_sum.mean(dim=1, keepdim=True) #[batch_size, 1, 1, 1]\n",
    "        channel_weight = F.sigmoid(channel_sum-channel_mean) #[batch_size, channel, 1, 1]\n",
    "        outputs = outputs * channel_weight\n",
    "        return outputs\n",
    "    \n",
    "    def remove(self):\n",
    "        self.handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9b7245",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook = ForwardDoctor(net, net.encoder.layer4[2].conv2)\n",
    "eval_net(net, val_loader, len(val), device, final=True, PR_curve_save_dir='./')\n",
    "net.eval()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06d6485",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook2 = ForwardDoctor(net, net.encoder.layer4[2].conv1)\n",
    "eval_net(net, val_loader, len(val), device, final=True, PR_curve_save_dir='./')\n",
    "net.eval()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ec36da",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook3 = ForwardDoctor(net, net.encoder.layer4[1].conv2)\n",
    "eval_net(net, val_loader, len(val), device, final=True, PR_curve_save_dir='./')\n",
    "net.eval()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd01acae",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook4 = ForwardDoctor(net, net.encoder.layer4[1].conv1)\n",
    "eval_net(net, val_loader, len(val), device, final=True, PR_curve_save_dir='./')\n",
    "net.eval()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f897f4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook5 = ForwardDoctor(net, net.encoder.layer4[0].conv2)\n",
    "hook6 = ForwardDoctor(net, net.encoder.layer4[0].conv1)\n",
    "eval_net(net, val_loader, len(val), device, final=True, PR_curve_save_dir='./')\n",
    "net.eval()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace880d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook.remove()\n",
    "hook2.remove()\n",
    "hook3.remove()\n",
    "hook4.remove()\n",
    "hook5.remove()\n",
    "hook6.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8284e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_net(net, val_loader, len(val), device, final=True, PR_curve_save_dir='./')\n",
    "net.eval()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8a503a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook = ForwardDoctor(net, net.encoder.layer4[2].bn2)\n",
    "eval_net(net, val_loader, len(val), device, final=True, PR_curve_save_dir='./')\n",
    "net.eval()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3988cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook2 = ForwardDoctor(net, net.encoder.layer4[2].bn1)\n",
    "eval_net(net, val_loader, len(val), device, final=True, PR_curve_save_dir='./')\n",
    "net.eval()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdd6c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook3 = ForwardDoctor(net, net.encoder.layer4[1].bn2)\n",
    "eval_net(net, val_loader, len(val), device, final=True, PR_curve_save_dir='./')\n",
    "net.eval()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125b4de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook4 = ForwardDoctor(net, net.encoder.layer4[1].bn1)\n",
    "eval_net(net, val_loader, len(val), device, final=True, PR_curve_save_dir='./')\n",
    "net.eval()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd847aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook5 = ForwardDoctor(net, net.encoder.layer4[0].bn2)\n",
    "hook6 = ForwardDoctor(net, net.encoder.layer4[0].bn1)\n",
    "eval_net(net, val_loader, len(val), device, final=True, PR_curve_save_dir='./')\n",
    "net.eval()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1248de5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook.remove()\n",
    "hook2.remove()\n",
    "hook3.remove()\n",
    "hook4.remove()\n",
    "hook5.remove()\n",
    "hook6.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd6d479",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook = ForwardDoctor(net, net.encoder.layer4[2].relu)\n",
    "eval_net(net, val_loader, len(val), device, final=True, PR_curve_save_dir='./')\n",
    "net.eval()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f39ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook2 = ForwardDoctor(net, net.encoder.layer4[1].relu)\n",
    "eval_net(net, val_loader, len(val), device, final=True, PR_curve_save_dir='./')\n",
    "net.eval()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5556352",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook3 = ForwardDoctor(net, net.encoder.layer4[0].relu)\n",
    "eval_net(net, val_loader, len(val), device, final=True, PR_curve_save_dir='./')\n",
    "net.eval()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb5391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook.remove()\n",
    "hook2.remove()\n",
    "hook3.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253ebb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_net(net, val_loader, len(val), device, final=True, PR_curve_save_dir='./')\n",
    "net.eval()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef23bb3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc93dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForwardNurse:\n",
    "    def __init__(self, module):\n",
    "        self.handle = module.register_forward_hook(self._modify_output)\n",
    "        self.channel_weight = None\n",
    "        \n",
    "    def _modify_output(self, module, inputs, outputs):\n",
    "        channel_sum = outputs.sum(dim=(2,3), keepdim=True) #[batch_size, channel, 1, 1]\n",
    "        channel_mean = channel_sum.mean(dim=1, keepdim=True) #[batch_size, 1, 1, 1]\n",
    "        channel_weight = F.sigmoid(channel_sum-channel_mean) #[batch_size, channel, 1, 1]\n",
    "        self.channel_weight = channel_weight.squeeze(-1).squeeze(-1) #[batch_size, channel]\n",
    "        outputs = outputs*(channel_weight>0.5).float()#outputs = outputs * channel_weight\n",
    "        return outputs\n",
    "    \n",
    "    def remove(self):\n",
    "        self.handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa4e7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook = ForwardNurse(net.encoder.layer4[2].bn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929236bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_gate_list = [[] for _ in range(n_classes)]\n",
    "for imgs, true_categories in tqdm(train_loader, total=len(train_loader), desc='Train Dataset', unit='batch', leave=True):\n",
    "    imgs = imgs.to(device=device, dtype=torch.float32)\n",
    "    true_categories = true_categories.to(device=device, dtype=torch.long)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        categories_pred = torch.softmax(net(imgs), dim=1)\n",
    "        labels_pred = categories_pred.argmax(dim=1)\n",
    "        for i in range(len(true_categories)):\n",
    "            if labels_pred[i] == true_categories[i]:\n",
    "                class_gate_list[true_categories[i].item()].append(hook.channel_weight[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7eb8af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(class_gate_list)):\n",
    "    class_gate_list[i] = torch.stack(class_gate_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f7ab81",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(figsize=(n_classes*5, 5*class_gate_list[0].shape[1]//10), nrows=class_gate_list[0].shape[1]//10, ncols=n_classes)\n",
    "for i, axs in (enumerate(axes) if isinstance(axes, np.ndarray) else enumerate([axes])):\n",
    "    for j, ax in (enumerate(axs) if isinstance(axs, np.ndarray) else enumerate([axs])):\n",
    "        ax.set_xlabel('value')\n",
    "        ax.set_ylabel('frequency')\n",
    "        ax.set_xlim(0,1)\n",
    "        sns.distplot(class_gate_list[j][:,i].cpu().numpy(), ax=ax, norm_hist=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b782ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1b5257",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum([1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c1d9be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
